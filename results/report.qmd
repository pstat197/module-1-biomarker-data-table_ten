---
title: "Biomarkers of ASD"
subtitle: "If you want a subtitle put it here"
author: "Brooks Piper, Srinidhi Satish, Adarsh Nagar, Nicole Xu, Quenlan, Nini"
date: last-modified
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

Use this as a template. Keep the headers and remove all other text. In all, your report can be quite short. When it is complete, render and then push changes to your team repository.

```{r}
# load any other packages and read data here
library(tidyverse)
```

# Abstract

Write a brief one-paragraph abstract that describes the contents of your write-up.

# Dataset

This data set was derived from Hewitson et al. (2021), observing and measuring Serum samples from a populous of 154 individuals comprised of 76 boys with ASD and 78 typically developing (TD) boys all between the ages of 18 months to 8 years. While each sample should appropriately analyze 1,125 proteins (since 192 of the 1,317 failed quality control), the exact proteins were left unidentified in the published study yielding following analyses based on the whole populous (1,317).Here, the two primary variable measurements are Autism Diagnostic Observation Schedule Scores (ADOS) and patient-attributed protein levels.

Prior to statistical testing, minor augmentations and adjustments were made in the preprocessing phase. Here, 'V1' is rewritten as 'name', 'V2' is rewritten as 'abbreviation', and all NA-named proteins are dropped. As a means to further clean the data set, columns with NA's are dropped to reduce sparsity, outliers are trimmed to reduce estimation-related abnormalities further in analysis, and protein levels are log transformed to standardize comparative data.

# Summary of published analysis

Summarize the methodology of the paper in 1-3 paragraphs. You need not explain the methods in depth as we did in class; just indicate what methods were used and how they were combined. If possible, include a diagram that depicts the methodological design. (Quarto has support for [GraphViz and Mermaid flowcharts](https://quarto.org/docs/authoring/diagrams.html).) Provide key results: the proteins selected for the classifier and the estimated accuracy.

# Findings

Summarize your findings here. I've included some subheaders in a way that seems natural to me; you can structure this section however you like.

## Impact of preprocessing and outliers

Log transformations are standard practice for ensuring data meets parametric assumptions for a number of hypothesis tests and statistical models. And reasonably, we can assume that a log-transformation was utilized for this exact reason. To confirm this hypothesis, we randomly selected three proteins, plotting their histograms which revealed strong right skews. We then applied the log-transformation and repeated this process for the same proteins, which produced normal and symmetric histograms. As a result, these data can be used in inference without any concern for assumption violations.

Aside from non-normal, skewed data, outliers are also present. To investigate patterns within the TD and ASD groups, we utilized the 1.5 IQR rule for each of the proteins. We first examined the top ten subjects with the most outliers, revealing that those in the TD group made up 70%. To get a more holistic perspective, we transitioned into looking at an aggregated sum of all outliers across groups, revealing that ASD and TD had 3334 and 3476, respectively. These results highlight the fact that while outlying protein levels in TD present as more extreme, ASD counts are more consistent.

## Methodological variations

a\) Repeat the analysis but carry out the entire selection procedure on a training partition

In this segment, data was split 80% training set and 20% test set before the entire selection procedure, performing statistical analyses and logistic regression model-fitting on training data prior to a final comparison with the unused test set. Test evaluation metrics yielded the following:

-   Sensitivity = 0.75

-   Specificity = 0.80

-   Accuracy ≈ 0.77

-   ROC AUC ≈ 0.87

The inherent expectation of evaluating metrics on unseen data may have been leaning towards lower estimates in all areas, however the above results are more indicative of the model's reasonably strong ability to identify true cases of both classes, differentiate between classes, and generate generally reliable predictions. Thus, while analysis was only carried out on a training partition, general accuracy in predictions on the test set remains high.

b\) Choose a larger number (more than ten) of top predictive proteins using each selection method

To examine how panel size affects performance, we repeated the selection process using larger sets of top predictive proteins (10–40) based on both *t*-test and random forest importance scores. The intersection of these sets was used to fit logistic regression models, and performance was evaluated on a held-out 20% test partition.

| Top Proteins | Sensitivity | Specificity | Accuracy |
|--------------|-------------|-------------|----------|
| 10           | 0.733       | 0.812       | 0.774    |
| 15           | 0.800       | 0.938       | 0.871    |
| 20           | 0.867       | 0.750       | 0.806    |
| 25           | 0.933       | 0.750       | 0.839    |
| 30           | 0.933       | 0.750       | 0.839    |
| 35           | 0.933       | 0.812       | 0.871    |
| 40           | 0.933       | 0.750       | 0.839    |

Accuracy remained relatively stable across models, fluctuating between **0.77 and 0.87**, while sensitivity generally increased with more proteins. Notably, using 15 or 35 top proteins yielded the highest accuracy (0.871) with strong sensitivity and specificity balance. These results suggest that expanding the protein set can improve sensitivity to ASD cases, though gains beyond 15–20 proteins offer diminishing returns. Overall, the classifier’s performance remained comparable to the in-class analysis, indicating that the original panel size was already near optimal for this dataset.

c\) Use a fuzzy intersection instead of a hard intersection to combine the sets of top predictive proteins across selection methods

The results show that the Fuzzy intersection model preforms better then both Hard intersection models. Yielding the highest ROC AUC and accuracy also improving sensitivity without losing specificity. Where the Hard intersection model has high specificity but the lowest specificity and AUC. Adding proteins to the Hard model makes the sensitivity match the Fuzzy model but reduces its specificity and AUC.

## Improved classifier

The classifier from the in class example's best performing accuracy was 0.774, taken from a panel of 5 proteins. In the analyses, we explored separate modifications to:

a\) Find a simpler panel that achieves comparable accuracy.

The benchmarked accuracy that is from the class example is 0.774, so that is what this experiment expected to replicated. Using a function that creates combinations of 2 different proteins and feeds the data into a Support Vector Machine classifier, it is shown that a 2 protein panel that consists of RELT and DERM produce classification accuracy of 0.774, which is comparable to the in class example, which utilized a 5 protein panel and a logistic regression classifier.

b\) Find an alternate panel that achieves better performing accuracy.
