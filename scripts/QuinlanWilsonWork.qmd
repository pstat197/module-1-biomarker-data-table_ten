---
title: "Biomarker Analysis"
author: "Quinlan Wilson"
format: html
---

```{r setup}
# --- Load libraries ---
library(tidyverse)
library(infer)
library(randomForest)
library(tidymodels)
library(modelr)
library(yardstick)

# --- Load data ---
setwd("C:/Users/quinl/OneDrive/Desktop/School/PSTAT197/module-1-biomarker-data-table_ten")
load('data/biomarker-clean.RData')
```

```{r}

## MULTIPLE TESTING
####################

# function to compute tests
test_fn <- function(.df){
  t_test(.df, 
         formula = level ~ group,
         order = c('ASD', 'TD'),
         alternative = 'two-sided',
         var.equal = F)
}

ttests_out <- biomarker_clean %>%
  # drop ADOS score
  select(-ados) %>%
  # arrange in long format
  pivot_longer(-group, 
               names_to = 'protein', 
               values_to = 'level') %>%
  # nest by protein
  nest(data = c(level, group)) %>% 
  # compute t tests
  mutate(ttest = map(data, test_fn)) %>%
  unnest(ttest) %>%
  # sort by p-value
  arrange(p_value) %>%
  # multiple testing correction
  mutate(m = n(),
         hm = log(m) + 1/(2*m) - digamma(1),
         rank = row_number(),
         p.adj = m*hm*p_value/rank)

# select significant proteins
proteins_s1 <- ttests_out %>%
  slice_min(p.adj, n = 10) %>%
  pull(protein)




## RANDOM FOREST
##################

# store predictors and response separately
predictors <- biomarker_clean %>%
  select(-c(group, ados))

response <- biomarker_clean %>% pull(group) %>% factor()

# fit RF
set.seed(101422)
rf_out <- randomForest(x = predictors, 
                       y = response, 
                       ntree = 1000, 
                       importance = T)


# compute importance scores
proteins_s2 <- rf_out$importance %>% 
  as_tibble() %>%
  mutate(protein = rownames(rf_out$importance)) %>%
  slice_max(MeanDecreaseGini, n = 10) %>%
  pull(protein)
## CORRELATION
#######################

corr_out <- biomarker_clean %>%
  select(-ados) %>%
  mutate(group = ifelse(group == "ASD", 1, 0)) %>%
  summarise(across(-group, ~ cor(.x, group))) %>%
  pivot_longer(everything(), names_to = "protein", values_to = "corr") %>%
  arrange(desc(abs(corr)))

proteins_s3 <- corr_out %>%
  slice_head(n = 10)

## RANK PROTEINS FROM EACH METHOD
#######################

rank_ttest <- ttests_out %>%
  arrange(p.adj) %>%
  mutate(rank_ttest = row_number()) %>%
  select(protein, rank_ttest)

rank_rf <- rf_out$importance %>%
  as_tibble(rownames = "protein") %>%
  arrange(desc(MeanDecreaseGini)) %>%
  mutate(rank_rf = row_number()) %>%
  select(protein, rank_rf)

rank_corr <- corr_out %>%
  mutate(rank_corr = rank(-abs(corr))) %>%
  select(protein, rank_corr)

## FIND FUZZY AND HARD INTERSECTION
#######################

fuzzy_ranks <- full_join(rank_ttest, rank_rf, by = "protein") %>%
  full_join(rank_corr, by = "protein") %>%
  mutate(mean_rank = rowMeans(across(starts_with("rank")))) %>%
  arrange(mean_rank)

proteins_fuzzy <- fuzzy_ranks %>%
  slice_min(mean_rank, n = 10) %>%
  pull(protein)
proteins_fuzzy



```

```{r}

# Define logistic regression function
logistic <- function(data, model_name, seed = 101422, prop = 0.8) {
  # Partition into training and test set
  set.seed(seed)
  split <- data %>% initial_split(prop = prop)
  
  # Fit logistic regression model
  fit <- glm(class ~ ., data = training(split), family = 'binomial')
  
  # Make predictions and compute metrics
  preds <- testing(split) %>%
    add_predictions(fit, type = 'response') %>%
    mutate(
      pred_class = factor(ifelse(pred > 0.5, "TRUE", "FALSE"), levels = c("FALSE", "TRUE")),
      class = factor(class, levels = c(FALSE, TRUE)),
      model = model_name
    )
  
  class_metrics <- metric_set(sensitivity, specificity, accuracy, roc_auc)
  metrics <- preds %>%
    class_metrics(truth = class, estimate = pred_class, pred, event_level = "second")
  
  list(preds = preds, fit = fit, metrics = metrics)
}

# Prepare datasets
biomarker_fuzzy <- biomarker_clean %>%
  select(group, any_of(proteins_fuzzy)) %>%
  mutate(class = (group == "ASD")) %>%
  select(-group)


# Run models
res_fuzzy <- logistic(biomarker_fuzzy, model_name = "Fuzzy Intersection")


# Combine predictions and compute summary metrics
all_preds <- bind_rows(res_fuzzy$preds) %>%
  mutate(pred = as.numeric(pred))

all_metrics <- all_preds %>%
  group_by(model) %>%
  summarise(
    sensitivity = sens_vec(class, pred_class),
    specificity = spec_vec(class, pred_class),
    accuracy = accuracy_vec(class, pred_class),
    roc_auc = roc_auc_vec(class, 1- pred)
  ) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>%
  bind_rows(tibble(
    model = "Hard Intersection",
    sensitivity = 0.812,
    specificity = 0.733,
    accuracy = 0.774,
    roc_auc = 0.883
  ))

all_metrics

```
The results show that the Fuzzy intersection model preforms better then the Hard intersection model. Yielding a sensitivity of 0.867, specificity of 0.875, accuracy of 0.871, and ROC AUC of 0.954 all of which are better than the hard intersection model. These values represent the fuzzy model being more balances and effective at distinguishing between ASD and TD subject without disproportionately favoring one group. The better performance is likely coming from its capacity to integrate partially overlapping information across selection methods(t-test, random forest, correlation test). By allowing proteins that appear in multiple but not all selection methods not risking dropping meaningful biomarkers that are emphasized by only some of the methods. 

